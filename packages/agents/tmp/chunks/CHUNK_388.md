sem contar que pra dados grandes talvesz vc precise da deepseek
esse pode ser util
se vc quiser instalo models do ollama que vc achar util
temos esses
Cursor
Ótimo esse inventário de modelos Ollama é bem completo e cobre praticamente todos os cenários do pipeline ALIVE Aqui está como podemos aproveitar cada grupo para o seu objetivo de segmentação sumarização e curadoria de datasets
 1 Segmentação e Sumarização de Conversas Contexto e Assunto
 Recomendados
 llama370b alta qualidade raciocínio avançado
 mistral8x7b ótimo para instrução e tarefas gerais
 wizardlm8x22b comandos complexos raciocínio
 openchat7b chat instrução robusto
 gemma7b eficiente bom para tarefas gerais
Esses modelos são ideais para
 Separar blocos de conversa por assuntocontexto
 Sumarizar o macrocontexto de cada bloco
 Gerar metadados explicativos
 2 Processamento de Dados Grandes ou Complexos
 Recomendado
 deepseekcoder33b excelente para compreensão de código e textos longos
 codellama70b alta qualidade para código mas também útil para textos longos
Se o dataset for muito extenso ou exigir raciocínio profundo esses modelos são mais robustos e podem lidar melhor com grandes volumes de texto