shellscript
ls l mediadataollama
shellscript
sudo chown R 10001000 mediadataollama
sudo chmod R 770 mediadataollama
yaml
volumes
 mediadataollamarootollama
shellscript
docker service update force nome_do_servi√ßo_ollama
User
time20250604T045803839Z levelINFO sourceroutesgo1234 msgserver config envmapCUDA_VISIBLE_DEVICES GPU_DEVICE_ORDINAL HIP_VISIBLE_DEVICES HSA_OVERRIDE_GFX_VERSION HTTPS_PROXY HTTP_PROXY NO_PROXY OLLAMA_CONTEXT_LENGTH4096 OLLAMA_DEBUGINFO OLLAMA_FLASH_ATTENTIONfalse OLLAMA_GPU_OVERHEAD0 OLLAMA_HOSThttp000011434 OLLAMA_INTEL_GPUfalse OLLAMA_KEEP_ALIVE5m0s OLLAMA_KV_CACHE_TYPE OLLAMA_LLM_LIBRARY OLLAMA_LOAD_TIMEOUT5m0s OLLAMA_MAX_LOADED_MODELS1 OLLAMA_MAX_QUEUE512 OLLAMA_MODELSrootollamamodels OLLAMA_MULTIUSER_CACHEfalse OLLAMA_NEW_ENGINEfalse OLLAMA_NOHISTORYfalse OLLAMA_NOPRUNEfalse OLLAMA_NUM_PARALLEL0 OLLAMA_ORIGINShttplocalhost httpslocalhost httplocalhost httpslocalhost http127001 https127001 http127001 https127001 http0000 https0000 http0000 https0000 app file tauri vscodewebview vscodefile OLLAMA_SCHED_SPREADfalse ROCR_VISIBLE_DEVICES http_proxy https_proxy no_proxy
time20250604T045805036Z levelINFO sourceimagesgo479 msgtotal blobs 9
time20250604T045805037Z levelINFO sourceimagesgo486 msgtotal unused blobs removed 0
time20250604T045805037Z levelINFO sourceroutesgo1287 msgListening on 11434 version 090
time20250604T045805037Z levelINFO sourcegpugo217 msglooking for compatible GPUs