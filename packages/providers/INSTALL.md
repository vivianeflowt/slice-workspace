# üöÄ Guia de Instala√ß√£o e Configura√ß√£o

Este guia explica como instalar e configurar o **Slice Providers - HuggingFace NLP Server**.

## ‚ö° Instala√ß√£o R√°pida

### 1. Pr√©-requisitos

```bash
# Verificar Python 3.10+
python3 --version

# Instalar PDM (gerenciador de depend√™ncias)
curl -sSL https://raw.githubusercontent.com/pdm-project/pdm/main/install-pdm.py | python3 -

# Ou via pip
pip install pdm

# Instalar Task (task runner)
# Ubuntu/Debian
sudo apt install task-runner

# macOS
brew install go-task/tap/go-task

# Ou baixar bin√°rio: https://taskfile.dev/installation/
```

### 2. Configura√ß√£o do Projeto

```bash
# Navegar para o diret√≥rio
cd packages/providers

# Instalar depend√™ncias e baixar modelos (pode demorar!)
task install

# ‚è≥ Este comando ir√°:
# - Instalar todas as depend√™ncias Python via PDM
# - Baixar modelos HuggingFace (~2-3GB total)
# - Configurar cache local de modelos
```

### 3. Primeira Execu√ß√£o

```bash
# Iniciar servidor em modo desenvolvimento
task dev

# ‚úÖ Se bem-sucedido, voc√™ ver√°:
# üöÄ Iniciando Slice Providers Server...
# üì° Servidor: 0.0.0.0:5115
# üíª CPU-only mode: True
# üì¶ Modelos baixados: 3
```

### 4. Testar API

```bash
# Em outro terminal, teste a API
curl http://localhost:5115/health

# Deve retornar algo como:
# {
#   "status": "healthy",
#   "version": "0.1.0",
#   "models": {
#     "classify": true,
#     "embed": true,
#     "pos_tag": true
#   }
# }
```

## üîß Resolu√ß√£o de Problemas

### Erro: "ModuleNotFoundError"

```bash
# Certifique-se de que PDM instalou as depend√™ncias
pdm list

# Se n√£o, reinstale
task install

# Ou manualmente
pdm install
```

### Erro: "Failed to download model"

```bash
# Verifique conex√£o com internet
ping huggingface.co

# Tente download manual dos modelos
python3 -c "from server.utils.model_downloader import download_default_models; download_default_models()"

# Limpe cache se necess√°rio
rm -rf ~/.cache/huggingface
```

### Erro: "CUDA out of memory" ou similar

```bash
# O servidor deve for√ßar CPU-only, mas se houver problemas:
export CUDA_VISIBLE_DEVICES=""
export FORCE_CPU_ONLY=true

# Reinicie o servidor
task dev
```

### Porta 5115 j√° est√° em uso

```bash
# Mude a porta via vari√°vel de ambiente
export PROVIDERS_PORT=5116
task dev

# Ou edite server/constants.py
```

## üß™ Valida√ß√£o da Instala√ß√£o

### Execute os testes

```bash
# Testes b√°sicos de estrutura
task test-unit

# Todos os testes (pode demorar)
task test

# Se algum teste falhar, verifique:
# 1. Todas as depend√™ncias instaladas
# 2. Modelos baixados corretamente
# 3. Permiss√µes de arquivo
```

### Teste manual das funcionalidades

```bash
# 1. Classifica√ß√£o
curl -X POST "http://localhost:5115/api/v1/classify" \
  -H "Content-Type: application/json" \
  -d '{"text": "Este produto √© excelente!"}'

# 2. Embeddings
curl -X POST "http://localhost:5115/api/v1/embed" \
  -H "Content-Type: application/json" \
  -d '{"text": "Processamento de linguagem natural"}'

# 3. POS Tagging
curl -X POST "http://localhost:5115/api/v1/pos-tag" \
  -H "Content-Type: application/json" \
  -d '{"text": "O gato subiu no telhado."}'
```

## üìä Monitoramento

### Verificar status do servidor

```bash
# Health check completo
curl http://localhost:5115/health | jq

# Informa√ß√µes do sistema
curl http://localhost:5115/info | jq

# Documenta√ß√£o da API
open http://localhost:5115/docs
```

### Verificar uso de recursos

```bash
# Modelos em cache
task models

# Limpar cache se necess√°rio
task clean

# Logs do servidor (modo dev mostra no terminal)
# Em produ√ß√£o, verificar logs em /var/log/ ou similar
```

## üîê Configura√ß√£o de Produ√ß√£o

### Vari√°veis de ambiente recomendadas

```bash
# .env.production
export PROVIDERS_PORT=5115
export PROVIDERS_HOST=0.0.0.0
export DEBUG=false
export LOG_LEVEL=INFO
export CPU_THREADS=4
export MODEL_CACHE_DIR=/opt/slice/models
```

### Executar em produ√ß√£o

```bash
# Servidor de produ√ß√£o (sem reload)
task start

# Ou com configura√ß√µes espec√≠ficas
uvicorn server.main:app --host 0.0.0.0 --port 5115 --workers 1
```

### Docker (opcional)

```bash
# Build da imagem
docker build -t slice-providers .

# Run do container
docker run -d -p 5115:5115 --name slice-providers slice-providers

# Verificar logs
docker logs slice-providers
```

## üìà Performance e Tuning

### Otimiza√ß√µes de CPU

```bash
# Configurar threads para sua CPU
export CPU_THREADS=$(nproc)  # Usa todos os cores
export OMP_NUM_THREADS=$CPU_THREADS
export MKL_NUM_THREADS=$CPU_THREADS
```

### Cache de modelos

```bash
# Pr√©-carregar todos os modelos na inicializa√ß√£o
# (reduz lat√™ncia da primeira requisi√ß√£o)
curl http://localhost:5115/api/v1/classify/info
curl http://localhost:5115/api/v1/embed/info
curl http://localhost:5115/api/v1/pos-tag/info
```

### Monitoramento de recursos

```bash
# Monitorar uso de CPU/mem√≥ria
htop

# Monitorar requisi√ß√µes
tail -f /var/log/slice-providers.log

# M√©tricas via API
curl http://localhost:5115/info | jq '.system'
```

## üÜò Suporte

### Se nada funcionar

1. **Verifique logs detalhados**:
   ```bash
   export DEBUG=true
   export LOG_LEVEL=DEBUG
   task dev
   ```

2. **Execute valida√ß√£o completa**:
   ```bash
   task validate
   ```

3. **Reinstale do zero**:
   ```bash
   task clean
   rm -rf .pdm.toml
   rm -rf __pycache__
   task install
   ```

4. **Abra uma issue** com:
   - OS e vers√£o Python
   - Logs de erro completos
   - Output de `task validate`
   - Output de `pdm list`

### Recursos adicionais

- üìñ **Documenta√ß√£o completa**: `http://localhost:5115/docs`
- üêõ **Report bugs**: GitHub Issues
- üí¨ **Discuss√µes**: GitHub Discussions
- üìß **Email**: dev@slice.com

---

**üéâ Sucesso!** Se chegou at√© aqui e tudo est√° funcionando, voc√™ tem um servidor NLP completo rodando em portugu√™s!

Pr√≥ximos passos:
- Explore a documenta√ß√£o em `/docs`
- Teste diferentes modelos de cada fun√ß√£o
- Integre com suas aplica√ß√µes
- Contribua com melhorias!
