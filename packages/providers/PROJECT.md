# ğŸ“˜ `PROJECT.md` â€” Servidor Local de Modelos NLP (HuggingFace, CPU-only, Estilo OpenAI)

> Estrutura para rodar modelos de NLP (foco em portuguÃªs) fora do Ollama, 100% em CPU, compatÃ­vel com a API da OpenAI. Modular, leve e fÃ¡cil de estender.

---

## ğŸ¯ Objetivo

- Servir modelos da Hugging Face nÃ£o disponÃ­veis no Ollama.
- Garantir compatibilidade com payloads OpenAI (onde fizer sentido).
- Operar totalmente em CPU, inclusive em mÃ¡quinas com GPU.
- Separar funÃ§Ãµes por *tipo de tarefa*, e nÃ£o por modelo.

---

## ğŸ¤” Por que esse servidor Ã© isolado?

| Motivo | Vantagem |
| --- | --- |
| **Evitar conflitos** | InstÃ¢ncias separadas para libs/modelos especÃ­ficos |
| **Facilidade de teste** | Rodar funÃ§Ãµes independentes, sem dependÃªncia cruzada |
| **Plugabilidade** | Substituir/adicionar modelos sem reescrever o sistema |
| **Escalabilidade** | Permite distribuir tarefas por mÃ¡quina sem centralizar tudo |
| **IndependÃªncia** | Funciona sem Cursor, Ollama, Docker ou qualquer stack fechado |

---

## ğŸ§© Estrutura de DiretÃ³rio Recomendada

```
server/
â”œâ”€â”€ api/                # Endpoints FastAPI por funÃ§Ã£o (classify, embed, etc)
â”‚   â”œâ”€â”€ classify.py
â”‚   â”œâ”€â”€ embed.py
â”‚   â””â”€â”€ pos_tag.py
â”œâ”€â”€ providers/          # ImplementaÃ§Ãµes especÃ­ficas dos modelos
â”‚   â”œâ”€â”€ classify/
â”‚   â”œâ”€â”€ embed/
â”‚   â””â”€â”€ pos_tag/
â”œâ”€â”€ services/           # OrquestraÃ§Ãµes e lÃ³gica de negÃ³cio
â”œâ”€â”€ models/             # Schemas Pydantic (v2)
â”œâ”€â”€ utils/              # Helpers reutilizÃ¡veis
â”œâ”€â”€ constants.py        # Configs gerais, modelos, timeouts
â””â”€â”€ main.py             # FastAPI app runner
```

---

## ğŸ§  ConvenÃ§Ã£o Central

> **Separar por tarefa**, nÃ£o por modelo.

**Exemplo certo:**

- `embed.py` â†’ usa `Ernie`, `multilingual-e5` ou outro embedding.

**Exemplo errado:**

- `bert_base_pt.py`, `roberta_embedder.py`, etc.

---

## âš™ï¸ Taskfile

```bash
task install     # Instala dependÃªncias e baixa os modelos
task run         # Roda o servidor na porta 5115
task test        # Executa testes automatizados
```

---

## ğŸ”— PadrÃ£o OpenAI: Payloads e Rotas

### Compatibilidade direta:

- `POST /v1/chat/completions`
- `POST /v1/embeddings`
- `POST /v1/classifications` *(rota extra, segue padrÃ£o JSON)*

### Payload de exemplo:

```json
{
  "model": "nome-do-modelo",
  "input": "texto em portuguÃªs para anÃ¡lise",
  "options": {
    "temperature": 0.7,
    "top_p": 0.9
  }
}
```

### Exemplo de retorno para embeddings:

```json
{
  "data": [
    {
      "embedding": [0.123, 0.345, ...],
      "index": 0
    }
  ],
  "model": "multilingual-e5",
  "object": "embedding"
}
```

---

## ğŸ§± PrincÃ­pios TÃ©cnicos

| PrincÃ­pio | DescriÃ§Ã£o |
| --- | --- |
| TestÃ¡vel | Cada funÃ§Ã£o Ã© testÃ¡vel isoladamente |
| Pydantic v2 | Todas as rotas validadas com schemas robustos |
| Sem mÃ¡gica | Sem globals ou configs escondidas |
| PlugÃ¡vel | FÃ¡cil trocar/adicionar funÃ§Ãµes sem quebrar nada |
| ExplicÃ¡vel | CÃ³digo comentado, com docstrings e convenÃ§Ãµes visÃ­veis |

---

## ğŸ§  Analogia mental

Cada funÃ§Ã£o Ã© como uma **tomada universal**: o agente IA (ou humano) pluga o modelo e ele funciona. Quer trocar o modelo? SÃ³ muda o plug â€” sem refazer a rede.

---

## ğŸ’¡ Casos de uso previstos

- ClassificaÃ§Ã£o de textos (ex: positivo, neutro, negativo)
- ExtraÃ§Ã£o de entidades nomeadas (NER)
- GeraÃ§Ã£o de embeddings
- Tagging de partes do discurso (POS)
- DetecÃ§Ã£o de linguagem
- Parafraseamento (futuro)
- CorreÃ§Ã£o gramatical (futuro)

---

## âœ… Compatibilidade mÃ­nima

| Item | Requisito |
| --- | --- |
| Python | >= 3.10 |
| Framework | FastAPI |
| Tipagem | Pydantic v2 |
| NLP base | `transformers` da Hugging Face |
| Runner | Taskfile |

---

## ğŸ“ TODO futuro

- [ ] Adicionar logging por agente
- [ ] IntegraÃ§Ã£o com roteador inteligente (model routing)
- [ ] Suporte a RAG leve (via context injection)
- [ ] Armazenamento local de histÃ³rico (DuckDB compatÃ­vel)
- [ ] Filtro semÃ¢ntico de entrada (prÃ©-processamento)

---

## ğŸ“ DiretÃ³rios externos opcionais

| DiretÃ³rio | Uso |
| --- | --- |
| `models/` | Pode ser externo via env (`MODELS_PATH`) |
| `outputs/` | Logs, resultados, cache (`OUTPUT_PATH`) |

---

## ğŸ” SeguranÃ§a

- RequisiÃ§Ãµes limitadas por IP (opcional)
- Logging de prompt (opcional, por agente)
- Headers de CORS configurados
- AutenticaÃ§Ã£o por token opcional para endpoints

---

## ğŸ“ Exemplo de uso real (no terminal)

```bash
curl http://localhost:5115/v1/classifications   -H "Content-Type: application/json"   -d '{
    "model": "classifier-pt-mini",
    "input": "o atendimento foi horrÃ­vel",
    "options": { "top_p": 0.8 }
  }'
```

Resposta esperada:

```json
{
  "label": "negativo",
  "confidence": 0.92,
  "model": "classifier-pt-mini"
}
```

---

## ğŸ—‚ï¸ Modo dev (para agentes)

> Agentes externos podem acessar esse servidor como se fosse uma OpenAI local.

- Endpoint: `http://localhost:5115/v1/...`
- Payload: igual ao OpenAI
- Pode rodar em mÃºltiplas mÃ¡quinas com modelos distintos

---

## ğŸ“¦ Lista de modelos suportados (iniciais)

| Tarefa | Modelo HuggingFace |
| --- | --- |
| Embeddings | `intfloat/multilingual-e5-small` |
| ClassificaÃ§Ã£o | `pierreguillou/bert-base-cased-sentiment-analysis` |
| POS Tagging | `gilf/flaubert-pt-pos` *(a confirmar)* |
| NER | `pierreguillou/ner-bert-portuguese-cased` |
| DetecÃ§Ã£o de lÃ­ngua | `papluca/xlm-roberta-base-language-detection` |

---

## ğŸ“Œ ObservaÃ§Ãµes finais

- Ideal para rodar em paralelo com seu cluster principal.
- Pode funcionar em conjunto com servidores Ollama, DeepSeek, Perplexity, etc.
- Arquitetado para escalar horizontalmente ou rodar em containers isolados.

---

> Criado para Viviane â€” visÃ£o tÃ©cnica e liberdade de agentes. ğŸ§ ğŸ”—
