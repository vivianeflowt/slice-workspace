# âœ… TASKS.md â€” Servidor Providers (Hugging Face) â€” Enterprise Edition

## ğŸ§ª Regra Geral de Qualidade
> Nenhuma task Ã© considerada **concluÃ­da** atÃ© que:
> 1. A funcionalidade esteja implementada e documentada
> 2. Um **teste automatizado** cubra e valide o comportamento
> 3. O teste esteja presente em `tests/` e rode com `task test`
> 4. O cÃ³digo siga padrÃµes de estilo, tipagem e documentaÃ§Ã£o
> 5. O PR tenha revisÃ£o cruzada (peer review)

---

## ğŸ”§ Estrutura Inicial e Base
- [ ] Criar pasta `server/` e `tests/` com `__init__.py` (estrutura mÃ­nima)
- [ ] Validar estrutura com `tests/test_structure.py`
  - **CritÃ©rio de aceitaÃ§Ã£o:** Falha se faltar qualquer pasta/arquivo essencial

## ğŸ”§ AutomaÃ§Ã£o e Taskfile
- [ ] Criar `Taskfile.yml` seguindo padrÃ£o Slice/ALIVE
- [ ] Implementar task `install` (PDM + download modelos Hugging Face)
- [ ] Validar automaÃ§Ã£o com `tests/test_taskfile.py` (subprocess)
  - **CritÃ©rio:** Task instala dependÃªncias e baixa modelos sem erro

## ğŸ”§ ModularizaÃ§Ã£o e Imports
- [ ] Criar `api/`, `services/`, `models/`, `utils/` (cada um com `__init__.py`)
- [ ] Validar imports e estrutura com `tests/test_modular_structure.py`
  - **CritÃ©rio:** Todos os mÃ³dulos importam sem erro

## ğŸ”§ FunÃ§Ãµes Puras, Testes e TDD
- [ ] Encapsular lÃ³gica Hugging Face em funÃ§Ãµes/classes puras
- [ ] Escrever testes antes da implementaÃ§Ã£o (TDD)
- [ ] Cobrir lÃ³gica com `tests/test_pure_logic.py` (mocks)
  - **CritÃ©rio:** FunÃ§Ãµes testÃ¡veis isoladamente, sem side effects

## ğŸ”§ Robustez e ValidaÃ§Ã£o
- [ ] Validar entradas nulas, invÃ¡lidas, limites e tipos
- [ ] Cobrir casos de borda com `tests/test_robustness.py` (`pytest.mark.parametrize`)
  - **CritÃ©rio:** FunÃ§Ãµes rejeitam entradas invÃ¡lidas corretamente

## ğŸ”§ Gerenciamento de DependÃªncias
- [ ] Rodar `pdm init` e configurar `pyproject.toml`
- [ ] Validar arquivos com `tests/test_pdm_files.py`
  - **CritÃ©rio:** Arquivos de dependÃªncia presentes e vÃ¡lidos

## ğŸ”§ ConsistÃªncia e IntegraÃ§Ã£o
- [ ] Validar compatibilidade estrutural com Command-R (`tests/test_base_consistency.py`)
  - **CritÃ©rio:** Estruturas compatÃ­veis e sem sobreposiÃ§Ã£o indevida

## ğŸ”§ ConfiguraÃ§Ã£o e Constants
- [ ] Centralizar configs em `constants.py` (porta, timeouts, modelos, etc)
- [ ] Validar ausÃªncia de nÃºmeros mÃ¡gicos com `tests/test_magic_numbers.py`
- [ ] Porta configurÃ¡vel validada por `tests/test_port_config.py`

## ğŸ”§ Taskfile como Interface
- [ ] Implementar tasks `dev`, `start`, `test`, `lint` no Taskfile
- [ ] Validar subprocessos com `tests/test_taskfile_commands.py`

## ğŸ”§ Compatibilidade OpenAI API
- [ ] Implementar mocks compatÃ­veis (ex: `/v1/chat/completions`)
- [ ] Cobrir endpoints com `tests/test_openai_api.py`

## ğŸ”§ DocumentaÃ§Ã£o e PadronizaÃ§Ã£o
- [ ] Garantir docstrings em todas funÃ§Ãµes/classes pÃºblicas
- [ ] Validar com `tests/test_docstrings.py` (`pydocstyle`)
- [ ] Escrever README incremental e exemplos de uso

## ğŸ”§ Layout e OrganizaÃ§Ã£o
- [ ] Validar estrutura e layout com `tests/test_folder_layout.py`

## ğŸ”§ Encapsulamento PlugÃ¡vel
- [ ] Criar `huggingface_service.py` plugÃ¡vel
- [ ] Cobrir mÃºltiplos modelos/mocks com `tests/test_huggingface_service.py`

## ğŸ”§ Foco Funcional e Endpoints
- [ ] Criar testes para tasks como `classificaÃ§Ã£o`, `parÃ¡frase`, `resumo` (`tests/test_functional_endpoints.py`)

## ğŸ”§ VisÃ£o Futura e Escalabilidade
- [ ] Testar mÃºltiplos servidores com `tests/test_parallel_server_spawning.py`
- [ ] Implementar cache local (in-memory por modelo) e validar com `tests/test_model_cache.py`

## ğŸ”§ Isolamento e SeguranÃ§a
- [ ] Garantir ausÃªncia de dependÃªncia com `command/` (`tests/test_provider_isolation.py`)
- [ ] Validar `device=cpu` em todos providers (`tests/test_cpu_only.py`)
- [ ] Garantir que nenhum provider tente acessar CUDA (`tests/test_no_cuda.py`)

---

## ğŸ” ExecuÃ§Ã£o ContÃ­nua e Boas PrÃ¡ticas

```bash
# Rodar todos os testes automatizados
$ task test
```

> **Boas prÃ¡ticas:**
> - Sempre escreva o teste antes da implementaÃ§Ã£o (TDD).
> - Cada task deve ser rastreÃ¡vel por commit, validada por teste e documentada.
> - Use tipagem, docstrings e siga padrÃµes de estilo (ex: black, isort, flake8).
> - PRs devem ser revisados por pelo menos 1 pessoa (peer review).
> - Documente decisÃµes arquiteturais relevantes no README ou em ADRs.

```bash
task test
